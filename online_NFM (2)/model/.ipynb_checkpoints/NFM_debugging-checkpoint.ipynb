{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import collections\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import data_preprocess\n",
    "\n",
    "result_dict = data_preprocess.read_criteo_data('../data/tiny_train_input.csv', '../data/category_emb.csv')\n",
    "test_dict = data_preprocess.read_criteo_data('../data/tiny_test_input.csv', '../data/category_emb.csv')\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    result_dict[key] = np.array(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFM(torch.nn.Module):\n",
    "    def __init__(self, field_size, feature_sizes, max_num_hidden_layers, qtd_neuron_per_hidden_layer,\n",
    "                 dropout_shallow=[0.5], embedding_size=4, n_classes=2, batch_size=1,\n",
    "                 verbose=False, interaction_type=True, eval_metric=roc_auc_score,\n",
    "                 b=0.99, n=0.01, s=0.2, use_cuda = True, greater_is_better = True):\n",
    "        super(NFM, self).__init__()\n",
    "\n",
    "        # Check CUDA\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            print(\"Using CUDA\")\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "        self.field_size = field_size\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.max_num_hidden_layers = max_num_hidden_layers\n",
    "        self.qtd_neuron_per_hidden_layer = qtd_neuron_per_hidden_layer\n",
    "        self.dropout_shallow = dropout_shallow\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.interaction_type = interaction_type\n",
    "        self.eval_metric = eval_metric\n",
    "        self.use_cuda = use_cuda\n",
    "        self.greater_is_better = greater_is_better\n",
    "\n",
    "        self.b = Parameter(torch.tensor(b), requires_grad=False).to(self.device)\n",
    "        self.n = Parameter(torch.tensor(n), requires_grad=False).to(self.device)\n",
    "        self.s = Parameter(torch.tensor(s), requires_grad=False).to(self.device)\n",
    "\n",
    "        # FM\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1)\n",
    "                                                     for feature_size in self.feature_sizes])\n",
    "        \n",
    "        if self.dropout_shallow:\n",
    "            self.first_order_dropout = nn.Dropout(self.dropout_shallow[0])\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size)\n",
    "                                                      for feature_size in self.feature_sizes])\n",
    "        self.bias = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "        # Neural Networks\n",
    "        self.hidden_layers = []\n",
    "        self.output_layers = []\n",
    "\n",
    "        if self.interaction_type:\n",
    "            self.hidden_layers.append(nn.Linear(embedding_size, qtd_neuron_per_hidden_layer))\n",
    "        else:\n",
    "            self.hidden_layers.append(nn.Linear(self.field_size * (self.field_size-1) / 2, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        for i in range(max_num_hidden_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(qtd_neuron_per_hidden_layer, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        for i in range(max_num_hidden_layers):\n",
    "            self.output_layers.append(nn.Linear(qtd_neuron_per_hidden_layer, n_classes))\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers).to(self.device)\n",
    "        self.output_layers = nn.ModuleList(self.output_layers).to(self.device)\n",
    "\n",
    "        self.alpha = Parameter(torch.Tensor(self.max_num_hidden_layers).fill_(1 / (self.max_num_hidden_layers + 1)),\n",
    "                               requires_grad=False).to(self.device)\n",
    "\n",
    "        self.loss_array = []\n",
    "\n",
    "        print(\"Initializing Neural Networks Done\")\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for i in range(self.max_num_hidden_layers):\n",
    "            self.output_layers[i].weight.grad.data.fill_(0)\n",
    "            self.output_layers[i].bias.grad.data.fill_(0)\n",
    "            self.hidden_layers[i].weight.grad.data.fill_(0)\n",
    "            self.hidden_layers[i].bias.grad.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, Xi, Xv):\n",
    "        # FM\n",
    "        Xi = torch.LongTensor(Xi).to(self.device).reshape((self.field_size, 1))\n",
    "        Xv = torch.FloatTensor(Xv).to(self.device)\n",
    "\n",
    "        first_order_emb_arr = [(torch.sum(emb(Xi[i]), 1) * Xv[i]).t()\n",
    "                               for i, emb in enumerate(self.first_order_embeddings)]\n",
    "        first_order = torch.cat(first_order_emb_arr, 0)\n",
    "\n",
    "        if self.dropout_shallow:\n",
    "            first_order = self.first_order_dropout(first_order)\n",
    "\n",
    "        if self.interaction_type:\n",
    "            # Use 2xixj = (xi+xj)^2 - xi^2 - yj^2 to reduce calculation\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi[i]), 1).t() * Xv[i]).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            print(second_order_emb_arr)\n",
    "            sum_second_order_emb = sum(second_order_emb_arr)\n",
    "            # (xi+xj)^2\n",
    "            sum_second_order_emb_square = sum_second_order_emb * sum_second_order_emb\n",
    "            # xi^2+xj^2\n",
    "            second_order_emb_square = [item * item for item in second_order_emb_arr]\n",
    "            second_order_emb_square_sum = sum(second_order_emb_square)\n",
    "            second_order = (sum_second_order_emb_square - second_order_emb_square_sum) * 0.5\n",
    "        else:\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi), 1).t() * Xv).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            weights_fm = []\n",
    "            for i in range(self.field_size):\n",
    "                for j in range(i + 1, self.field_size):\n",
    "                    weights_fm.append(second_order_emb_arr[i] * second_order_emb_arr[j])\n",
    "\n",
    "        # Neural Networks\n",
    "        if self.interaction_type:\n",
    "            x = second_order\n",
    "        else:\n",
    "            x = torch.cat([torch.sum(weight_fm, 1).view([-1, 1])\n",
    "                            for weight_fm in weights_fm], 1)\n",
    "        hidden_connections = []\n",
    "        activation = F.relu\n",
    "\n",
    "        x = activation(self.hidden_layers[0](x))\n",
    "        hidden_connections.append(x)\n",
    "\n",
    "        for i in range(1, self.max_num_hidden_layers):\n",
    "            hidden_connections.append(\n",
    "                F.relu(self.hidden_layers[i](hidden_connections[i - 1])))\n",
    "\n",
    "        output_class = []\n",
    "\n",
    "        for i in range(self.max_num_hidden_layers):\n",
    "            output_class.append(self.output_layers[i](hidden_connections[i]))\n",
    "\n",
    "        pred_per_layer = torch.stack(output_class)\n",
    "\n",
    "        return first_order, pred_per_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update_weights(self, Xi, Xv, Y, show_loss):\n",
    "        Y = torch.LongTensor(Y).to(self.device)\n",
    "        first_order, predictions_per_layer = self.forward(Xi, Xv)\n",
    "\n",
    "        losses_per_layer = []\n",
    "\n",
    "        for out in predictions_per_layer:\n",
    "            criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = criterion(out.view(self.batch_size, self.n_classes),\n",
    "                             Y.view(self.batch_size).long())\n",
    "            losses_per_layer.append(loss)\n",
    "\n",
    "        w = []\n",
    "        b = []\n",
    "\n",
    "        for i in range(len(losses_per_layer)):\n",
    "            losses_per_layer[i].backward(retain_graph=True)\n",
    "            self.output_layers[i].weight.data -= self.n * \\\n",
    "                self.alpha[i] * self.output_layers[i].weight.grad.data\n",
    "            self.output_layers[i].bias.data -= self.n * \\\n",
    "                self.alpha[i] * self.output_layers[i].bias.grad.data\n",
    "            w.append(self.alpha[i] * self.hidden_layers[i].weight.grad.data)\n",
    "            b.append(self.alpha[i] * self.hidden_layers[i].bias.grad.data)\n",
    "            self.zero_grad()\n",
    "\n",
    "        for i in range(1, len(losses_per_layer)):\n",
    "            self.hidden_layers[i].weight.data -= self.n * torch.sum(torch.cat(w[i:]))\n",
    "            self.hidden_layers[i].bias.data -= self.n * torch.sum(torch.cat(b[i:]))\n",
    "\n",
    "        for i in range(len(losses_per_layer)):\n",
    "            self.alpha[i] *= torch.pow(self.b, losses_per_layer[i])\n",
    "            self.alpha[i] = torch.max(self.alpha[i], self.s / self.max_num_hidden_layers)\n",
    "\n",
    "        z_t = torch.sum(self.alpha)\n",
    "\n",
    "        self.alpha = Parameter(self.alpha / z_t, requires_grad=False).to(self.device)\n",
    "\n",
    "        if show_loss:\n",
    "            real_output = torch.sum(torch.mul(\n",
    "                self.alpha.view(self.max_num_hidden_layers, 1).repeat(1, self.batch_size).view(\n",
    "                    self.max_num_hidden_layers, self.batch_size, 1), predictions_per_layer), 0)\n",
    "            criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = criterion(real_output.view(self.batch_size, self.n_classes), Y.view(self.batch_size).long())\n",
    "            self.loss_array.append(loss)\n",
    "            if (len(self.loss_array) % 1000) == 0:\n",
    "                print(\"WARNING: Set 'show_loss' to 'False' when not debugging. \"\n",
    "                      \"It will deteriorate the fitting performance.\")\n",
    "                loss = torch.Tensor(self.loss_array).mean().cpu().numpy()\n",
    "                print(\"Alpha:\" + str(self.alpha.data.cpu().numpy()))\n",
    "                print(\"Training Loss: \" + str(loss))\n",
    "                self.loss_array.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def partial_fit_(self, Xi_data, Xv_data, Y_data, show_loss=True):\n",
    "        self.update_weights(Xi_data, Xv_data, Y_data, show_loss)\n",
    "\n",
    "    def partial_fit(self, Xi_data, Xv_data, Y_data, show_loss=True):\n",
    "        self.partial_fit_(Xi_data, Xv_data, Y_data, show_loss)\n",
    "\n",
    "    def predict_(self, Xi_data, Xv_data):\n",
    "        return torch.argmax(torch.sum(torch.mul(\n",
    "            self.alpha.view(self.max_num_hidden_layers, 1).repeat(1, 1).view(\n",
    "                self.max_num_hidden_layers, 1, 1), self.forward(Xi_data, Xv_data)[1]), 0), dim=1).cpu().numpy()\n",
    "\n",
    "    def predict(self, Xi_data, Xv_data):\n",
    "        pred = self.predict_(Xi_data, Xv_data)\n",
    "        return pred\n",
    "\n",
    "    def plot_accuracy(self, Xi_data, Xv_data, Y_data):\n",
    "        right_pred = 0\n",
    "        result = []\n",
    "\n",
    "        for i in range(len(Y_data)):\n",
    "            ## prediction part\n",
    "            pred = self.predict(Xi_data[i], Xv_data[i])\n",
    "            \n",
    "            if (Y_data[i] == pred[i]):\n",
    "                right_pred += 1\n",
    "            result.append(right_pred / (i + 1) * 100)\n",
    "\n",
    "            ## Online NN part update\n",
    "            self.update_weights(Xi_data[i], Xv_data[i], Y_data, show_loss=False)\n",
    "\n",
    "\n",
    "        plt.plot([i for i in range(len(result))], result)\n",
    "        plt.ylim(-4, 104)\n",
    "        plt.xlabel('Number of Data')\n",
    "        plt.ylabel('Right Predictions / Whole Predictions * 100 (%)')\n",
    "\n",
    "        plt.grid()\n",
    "        plt.title('Accuracy')\n",
    "\n",
    "        plt.savefig(f'Accuracy{time()}.png')\n",
    "        plt.show()\n",
    "\n",
    "        print(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Initializing Neural Networks Done\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    nfm = NFM(39, result_dict['feature_sizes'], max_num_hidden_layers=5,\n",
    "              qtd_neuron_per_hidden_layer=10, verbose=True, use_cuda=True, interaction_type=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 1], m2: [4 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ce6a22ac245e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a9e902638523>\u001b[0m in \u001b[0;36mplot_accuracy\u001b[0;34m(self, Xi_data, Xv_data, Y_data)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m## prediction part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mright_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9e902638523>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xi_data, Xv_data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXi_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9e902638523>\u001b[0m in \u001b[0;36mpredict_\u001b[0;34m(self, Xi_data, Xv_data)\u001b[0m\n\u001b[1;32m    188\u001b[0m         return torch.argmax(torch.sum(torch.mul(\n\u001b[1;32m    189\u001b[0m             self.alpha.view(self.max_num_hidden_layers, 1).repeat(1, 1).view(\n\u001b[0;32m--> 190\u001b[0;31m                 self.max_num_hidden_layers, 1, 1), self.forward(Xi_data, Xv_data)[1]), 0), dim=1).cpu().numpy()\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXi_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9e902638523>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Xi, Xv)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mhidden_connections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 1], m2: [4 x 10] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268"
     ]
    }
   ],
   "source": [
    "    nfm.plot_accuracy(result_dict['index'], result_dict['value'], result_dict['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
