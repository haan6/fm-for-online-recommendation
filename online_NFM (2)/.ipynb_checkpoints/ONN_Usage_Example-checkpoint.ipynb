{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugTEiBmBV3Cc"
   },
   "source": [
    "#Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FbEX3YFwKCxy",
    "outputId": "ce12c48c-690e-49cb-c8a1-b31f66872022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onn\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/72/62b4ad29833c4eda451f70968176077cffd2350d5c866cfe7f7e1bbb86cd/onn-0.1.8.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/yeji/Myenv/lib/python3.6/site-packages (from onn) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: torch in /home/yeji/Myenv/lib/python3.6/site-packages (from onn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: mabalgs in /home/yeji/Myenv/lib/python3.6/site-packages (from onn) (0.6.4)\n",
      "Building wheels for collected packages: onn\n",
      "  Building wheel for onn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for onn: filename=onn-0.1.8-cp36-none-any.whl size=4622 sha256=662cb84043ee0a17b40ce18b3ab302f77479df605b2b612798222c2ef1f68eac\n",
      "  Stored in directory: /home/yeji/.cache/pip/wheels/4d/71/b9/e3926169b45fd521f1f914c0c37b88d9d621cb5c511e1d1ea1\n",
      "Successfully built onn\n",
      "Installing collected packages: onn\n",
      "Successfully installed onn-0.1.8\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade onn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "CCBv8CqCe5Ao",
    "outputId": "a9c5bc86-af25-4b3a-b827-a5e22c1b2a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl (173kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 965kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11 in /home/yeji/Myenv/lib/python3.6/site-packages (from imbalanced-learn) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /home/yeji/Myenv/lib/python3.6/site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/yeji/Myenv/lib/python3.6/site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21 in /home/yeji/Myenv/lib/python3.6/site-packages (from imbalanced-learn) (0.21.2)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.5.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbYfcIpkV-SA"
   },
   "source": [
    "##Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9xT-ZdVsKH6z",
    "outputId": "899e5370-ad08-40cc-8241-9a577717d828"
   },
   "outputs": [],
   "source": [
    "from onn.OnlineNeuralNetwork import ONN\n",
    "from onn.OnlineNeuralNetwork import ONN_THS\n",
    "from sklearn.datasets import make_classification, make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from imblearn.datasets import make_imbalance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9H22wxBWB9f"
   },
   "source": [
    "## Initializing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wOHgHL1LieT"
   },
   "outputs": [],
   "source": [
    "onn_network = ONN(features_size=10, max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=40, n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYqkIyxyWI2h"
   },
   "source": [
    "##Creating Fake Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXgNSF9gL69F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = make_classification(n_samples=50000, n_features=10, n_informative=4, n_redundant=0, n_classes=10,\n",
    "                           n_clusters_per_class=1, class_sep=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THGPFSWJWPEm"
   },
   "source": [
    "##Learning and predicting at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "70J3ZYtmL-Zm",
    "outputId": "15babeef-1128-44b7-8dcf-92d4ef3d295a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000,)\n",
      "Online Accuracy: 0.9810896491203455\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399341  0.04001645 0.04001645 0.04001645 0.04001645]\n",
      "Training Loss: 0.12539339\n",
      "(15000,)\n",
      "Online Accuracy: 0.9814242685445789\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399798  0.04000502 0.04000502 0.04000502 0.04000502]\n",
      "Training Loss: 0.15348464\n",
      "(15000,)\n",
      "Online Accuracy: 0.9804514189689044\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399658  0.04000853 0.04000853 0.04000853 0.04000853]\n",
      "Training Loss: 0.1678719\n",
      "(15000,)\n",
      "Online Accuracy: 0.9803178963189874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d18984b24d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0monn_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monn_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/research/online_NFM/onn/OnlineNeuralNetwork.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X_data, Y_data, show_loss)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/research/online_NFM/onn/OnlineNeuralNetwork.py\u001b[0m in \u001b[0;36mpartial_fit_\u001b[0;34m(self, X_data, Y_data, show_loss)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/research/online_NFM/onn/OnlineNeuralNetwork.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, X, Y, show_loss)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_per_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/research/online_NFM/onn/OnlineNeuralNetwork.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_abs_string_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Myenv/local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m_get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Get the absolute index for the list of modules\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index {} is out of range'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    onn_network.partial_fit(np.asarray([X_train[i, :]]), np.asarray([y_train[i]]))\n",
    "  \n",
    "    if i % 1000 == 0:\n",
    "        predictions = onn_network.predict(X_test)\n",
    "        print(\"Online Accuracy: {}\".format(balanced_accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K01fvy7Tj7Z"
   },
   "source": [
    "# Learning in batch with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jg1UJWvDTjJc",
    "outputId": "b917847a-45a3-445f-c527-3d449e1de377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA :]\n"
     ]
    }
   ],
   "source": [
    "onn_network = ONN(features_size=10, max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=40, n_classes=10, batch_size=10, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uoxk5Jk_UYKJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, Y):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      X = self.X[idx],\n",
    "      Y = self.Y[idx]\n",
    "\n",
    "      return X, Y\n",
    "    \n",
    "transformed_dataset = Dataset(X_train, y_train)\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=10,shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "8jz4S-SVUAMx",
    "outputId": "eb25d974-e8af-4e51-e9f0-5f2501b02b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83902884 0.04024278 0.04024278 0.04024278 0.04024278]\n",
      "Training Loss: 1.577592\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8394673  0.04013318 0.04013318 0.04013318 0.04013318]\n",
      "Training Loss: 0.5495532\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8397412 0.0400647 0.0400647 0.0400647 0.0400647]\n",
      "Training Loss: 0.40501082\n"
     ]
    }
   ],
   "source": [
    "for local_X, local_y in dataloader: \n",
    "  onn_network.partial_fit(np.squeeze(torch.stack(local_X).numpy()), local_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u7XwSO6zVpsz",
    "outputId": "6f19825b-4435-442c-c710-4003ef7b555c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517950352535276\n"
     ]
    }
   ],
   "source": [
    "predictions = onn_network.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(balanced_accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSk4Fl4GV9NG"
   },
   "source": [
    "#Using contextual bandit - ONN_THS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBweUP_CZaFz"
   },
   "source": [
    "In this example the ONN acts like a contextual bandits a reinforcement learning algorithm type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeFBn4erUDY3"
   },
   "outputs": [],
   "source": [
    "X_linear, Y_linear = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1, class_sep=200, shuffle=True)\n",
    "X_non_linear, Y_non_linear = make_circles(n_samples=10000, noise=0.1, factor=0.3, shuffle=True)\n",
    "X_linear_2, Y_linear_2 = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1, class_sep=200, shuffle=True)\n",
    "\n",
    "X_linear_train = X_linear[:5000]\n",
    "Y_linear_train = Y_linear[:5000]\n",
    "\n",
    "X_linear_test = X_linear[5000:]\n",
    "Y_linear_test = Y_linear[5000:]\n",
    "\n",
    "X_non_linear_train = X_non_linear[:5000]\n",
    "Y_non_linear_train = Y_non_linear[:5000]\n",
    "\n",
    "X_non_linear_test = X_non_linear[5000:]\n",
    "Y_non_linear_test = Y_non_linear[5000:]\n",
    "\n",
    "X_linear_train_2 = X_linear_2[:5000]\n",
    "Y_linear_train_2 = Y_linear_2[:5000]\n",
    "\n",
    "X_linear_test_2 = X_linear_2[5000:]\n",
    "Y_linear_test_2 = Y_linear_2[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfnN1xG7WtF7"
   },
   "outputs": [],
   "source": [
    "gp = ONN_THS(2, 5, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7EmKF-y8Wytt",
    "outputId": "b6b7b943-d466-4274-cd11-e1325290412b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 7.708073e-07\n",
      "======================================================\n",
      "Accuracy: 0.9320135479448636\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.66480255 0.08414558 0.08314086 0.08373952 0.0841715 ]\n",
      "Training Loss: 1.4113159\n",
      "======================================================\n",
      "Accuracy: 0.7803689523703463\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.4597675  0.1319707  0.13887632 0.13379806 0.13558747]\n",
      "Training Loss: 2.1171865\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.8254292\n",
      "======================================================\n",
      "Accuracy: 0.8239034376118035\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 1.9921635\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.09616726 0.22576231 0.22466676 0.22605874 0.2273449 ]\n",
      "Training Loss: 1.2512604\n",
      "======================================================\n",
      "Accuracy: 0.9194272332380344\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.7483906  0.06154997 0.0657564  0.0615586  0.06274442]\n",
      "Training Loss: 1.2462758\n",
      "======================================================\n",
      "Accuracy: 0.9089153835864292\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 1.1584326\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 1.0460584\n",
      "======================================================\n",
      "Accuracy: 0.9091254701747447\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.04581921 0.22431232 0.26757908 0.22434013 0.23794925]\n",
      "Training Loss: 1.4130515\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.00093426596\n",
      "======================================================\n",
      "Accuracy: 0.9230967883152815\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 1.7778293\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9200642132137263\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.1015042  0.22482882 0.22428374 0.22482881 0.22455448]\n",
      "Training Loss: 1.1210397\n",
      "======================================================\n",
      "Accuracy: 0.9140752253990685\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.00011777431\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.13615824 0.21326509 0.22357734 0.21326567 0.21373361]\n",
      "Training Loss: 1.4623655\n",
      "======================================================\n",
      "Accuracy: 0.9162808945688536\n",
      "======================================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    for i in range(len(X_linear_train)):\n",
    "        x = np.asarray([X_linear_train[i, :]])\n",
    "        y = np.asarray([Y_linear_train[i]])\n",
    "\n",
    "        arm, exp = gp.predict(x)\n",
    "        \n",
    "        if arm == y[0]:  \n",
    "          gp.partial_fit(x, y, exp)\n",
    "          \n",
    "        if i % 2000 == 1999:\n",
    "          pred = []\n",
    "          print(\"======================================================\")\n",
    "          for i in range(len(X_linear_test)):  \n",
    "            pred.append(gp.predict(np.asarray([X_linear_test[i, :]]))[0])\n",
    "          print(\"Accuracy: \" + str(balanced_accuracy_score(Y_linear_test, pred)))\n",
    "          print(\"======================================================\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G6myrkQjW1kj",
    "outputId": "873af04f-482d-4ae5-89fe-8df04f21cc38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.7324713  0.06278172 0.07632934 0.0627818  0.06563586]\n",
      "Training Loss: 0.565434\n",
      "======================================================\n",
      "Accuracy: 0.4978415196546431\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83837765 0.04006734 0.04134858 0.04006734 0.04013911]\n",
      "Training Loss: 0.32934776\n",
      "======================================================\n",
      "Accuracy: 0.6431012228961956\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83944225 0.04013941 0.04013941 0.04013941 0.04013941]\n",
      "Training Loss: 0.27433354\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83982235 0.04004439 0.04004439 0.04004439 0.04004439]\n",
      "Training Loss: 0.2834035\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83984315 0.04003919 0.04003919 0.04003919 0.04003919]\n",
      "Training Loss: 0.2099059\n",
      "======================================================\n",
      "Accuracy: 0.7659370825499332\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8395842  0.04010393 0.04010393 0.04010393 0.04010393]\n",
      "Training Loss: 0.21292916\n",
      "======================================================\n",
      "Accuracy: 0.9151972664315626\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83984536 0.04003864 0.04003864 0.04003864 0.04003864]\n",
      "Training Loss: 0.19620447\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8398821  0.04002946 0.04002946 0.04002946 0.04002946]\n",
      "Training Loss: 0.16505778\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83968943 0.04007762 0.04007762 0.04007762 0.04007762]\n",
      "Training Loss: 0.14461489\n",
      "======================================================\n",
      "Accuracy: 0.9197904671664747\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399311  0.04001722 0.04001722 0.04001722 0.04001722]\n",
      "Training Loss: 0.124461606\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8396594  0.04008514 0.04008514 0.04008514 0.04008514]\n",
      "Training Loss: 0.115024015\n",
      "======================================================\n",
      "Accuracy: 0.9301949488311918\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8398307  0.04004231 0.04004231 0.04004231 0.04004231]\n",
      "Training Loss: 0.10779811\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8398185  0.04004535 0.04004535 0.04004535 0.04004535]\n",
      "Training Loss: 0.099823594\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399364  0.04001588 0.04001588 0.04001588 0.04001588]\n",
      "Training Loss: 0.092471905\n",
      "======================================================\n",
      "Accuracy: 0.8999838239974118\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.839942   0.04001448 0.04001448 0.04001448 0.04001448]\n",
      "Training Loss: 0.08162724\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83992773 0.04001804 0.04001804 0.04001804 0.04001804]\n",
      "Training Loss: 0.0805736\n",
      "======================================================\n",
      "Accuracy: 0.9387956702073073\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83965665 0.04008581 0.04008581 0.04008581 0.04008581]\n",
      "Training Loss: 0.081078894\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8397386  0.04006533 0.04006533 0.04006533 0.04006533]\n",
      "Training Loss: 0.072354406\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399574  0.04001063 0.04001063 0.04001063 0.04001063]\n",
      "Training Loss: 0.06984673\n",
      "======================================================\n",
      "Accuracy: 0.9489987918398066\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399927 0.0400018 0.0400018 0.0400018 0.0400018]\n",
      "Training Loss: 0.06360293\n",
      "======================================================\n",
      "Accuracy: 0.9428014308482289\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.83996755 0.0400081  0.0400081  0.0400081  0.0400081 ]\n",
      "Training Loss: 0.06630126\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    for i in range(len(X_non_linear_train)):\n",
    "        x = np.asarray([X_non_linear_train[i, :]])\n",
    "        y = np.asarray([Y_non_linear_train[i]])\n",
    "\n",
    "        arm, exp = gp.predict(x)\n",
    "        \n",
    "        if arm == y[0]:  \n",
    "          gp.partial_fit(x, y, exp)\n",
    "          \n",
    "        if i % 2000 == 1999:\n",
    "          pred = []\n",
    "          print(\"======================================================\")\n",
    "          for i in range(len(X_linear_test)):  \n",
    "            pred.append(gp.predict(np.asarray([X_non_linear_test[i, :]]))[0])\n",
    "          print(\"Accuracy: \" + str(balanced_accuracy_score(Y_non_linear_test, pred)))\n",
    "          print(\"======================================================\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G27Vh6mI6LTi"
   },
   "source": [
    "# Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-IHNagYXgap"
   },
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_samples=110000, n_features=20, n_classes=10, n_informative=8, n_redundant=0, n_clusters_per_class=1, class_sep=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5Mh3jR-6TWR"
   },
   "outputs": [],
   "source": [
    "X_t, Y_t = make_imbalance(X, Y, sampling_strategy={0: 800, 1: 5000, 2: 10000, 3: 10000, 4: 1000, 5: 1000, 6: 500, 7: 10000, 8: 5000, 9:5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryU12keU6WOp"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_t, Y_t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Si9uRxRu7Ecw"
   },
   "outputs": [],
   "source": [
    "gp = ONN_THS(20, 5, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "a21-OBBC6YrK",
    "outputId": "9285bd62-10a5-4f71-b8ec-22097ae3a808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Accuracy: 0.4353221256829899\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.06869241 0.16809322 0.3725306  0.17724589 0.21343793]\n",
      "Training Loss: 9.325638\n",
      "======================================================\n",
      "Accuracy: 0.4386085948153132\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.11643752 0.20428126 0.23810413 0.20844749 0.23272966]\n",
      "Training Loss: 11.25701\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 2.6811903\n",
      "======================================================\n",
      "Accuracy: 0.6928950497293518\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 10.146265\n",
      "======================================================\n",
      "Accuracy: 0.6838257488564606\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 8.005989\n",
      "======================================================\n",
      "Accuracy: 0.6115088279471166\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.79145914 0.05235159 0.05036381 0.05197832 0.05384716]\n",
      "Training Loss: 3.7819355\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 8.093227\n",
      "======================================================\n",
      "Accuracy: 0.7768358673631839\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.7728323692342458\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.7750311850166554\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.23982884 0.19055171 0.18932813 0.19059701 0.18969429]\n",
      "Training Loss: 13.883859\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8685216303769551\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8026281358448346\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 17.250746\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 2.5108016\n",
      "======================================================\n",
      "Accuracy: 0.8674449681421013\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8713122081601006\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.86805856622274\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8673653690806932\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8709340126479518\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 26.645742\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.5200308  0.12016081 0.11971524 0.12033709 0.11975605]\n",
      "Training Loss: 5.1447864\n",
      "======================================================\n",
      "Accuracy: 0.7919937075157115\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 16.11202\n",
      "======================================================\n",
      "Accuracy: 0.8733754651900446\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8717504131399775\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.873564110770424\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 15.066921\n",
      "======================================================\n",
      "Accuracy: 0.7295902241565401\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 2.8158276\n",
      "======================================================\n",
      "Accuracy: 0.8713796789076305\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 22.253164\n",
      "======================================================\n",
      "Accuracy: 0.8771001088342661\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.53331    0.11533871 0.11965422 0.11555222 0.1161448 ]\n",
      "Training Loss: 13.497225\n",
      "======================================================\n",
      "Accuracy: 0.8746053463042536\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 4.758543\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8741468052285819\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8795648644911169\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 16.302721\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 3.1496372\n",
      "======================================================\n",
      "Accuracy: 0.8837012263713927\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.902540151229202\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9021177354976991\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 8.878667\n",
      "======================================================\n",
      "Accuracy: 0.8079567207927605\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8039658939000326\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 6.192695\n",
      "======================================================\n",
      "Accuracy: 0.9009930184879561\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 10.917292\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.900008182367175\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.7559461  0.06102359 0.0612076  0.0608501  0.06097254]\n",
      "Training Loss: 10.377898\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9055045133877494\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9021639784287858\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 10.628485\n",
      "======================================================\n",
      "Accuracy: 0.9016796783336091\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 8.878321\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8994004273359604\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9050839928229234\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9044701066116776\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9047566712793573\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9063798424927105\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9008264580869225\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9001214892044537\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.902945101154504\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9009983483663652\n",
      "======================================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    x = np.asarray([X_train[i, :]])\n",
    "    y = np.asarray([y_train[i]])\n",
    "\n",
    "    arm, exp = gp.predict(x)\n",
    "\n",
    "    if arm == y[0]:  \n",
    "      gp.partial_fit(x, y, exp)\n",
    "\n",
    "    if i % 2000 == 1999:\n",
    "      pred = []\n",
    "      print(\"======================================================\")\n",
    "      for i in range(len(X_test)):  \n",
    "        pred.append(gp.predict(np.asarray([X_test[i, :]]))[0])\n",
    "      print(\"Accuracy: \" + str(balanced_accuracy_score(y_test, pred)))\n",
    "      print(\"======================================================\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqBRyZxh-6_h"
   },
   "outputs": [],
   "source": [
    "gp = ONN_THS(20, 5, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mFFz2xWN6o_4",
    "outputId": "ee7d349a-2efb-44b3-d44c-7a1976c903a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.31641227 0.12936862 0.17681654 0.18663488 0.19076766]\n",
      "Training Loss: 4.9937906\n",
      "======================================================\n",
      "Accuracy: 0.5121877357778365\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.11614554 0.1702754  0.2646138  0.1885041  0.2604611 ]\n",
      "Training Loss: 9.42681\n",
      "======================================================\n",
      "Accuracy: 0.60000532007458\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 3.760187\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.6370007505514537\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.6198465258532846\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 1.579348\n",
      "======================================================\n",
      "Accuracy: 0.5121875529066693\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 9.70304\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.6330198059531864\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 10.2148285\n",
      "======================================================\n",
      "Accuracy: 0.7084962849287858\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.7265182796040035\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.7239405864519876\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.12717529\n",
      "======================================================\n",
      "Accuracy: 0.810706833334715\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 9.516822\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 2.7376916\n",
      "======================================================\n",
      "Accuracy: 0.8972895582247269\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 8.428832\n",
      "======================================================\n",
      "Accuracy: 0.90217251261295\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 11.3074665\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9124533480316206\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9035376710667149\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9045845614725639\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.6930886  0.07199327 0.08099582 0.07299026 0.08093201]\n",
      "Training Loss: 12.486347\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8146383732762196\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.8232097488414242\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 6.5098047\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9154437246746809\n",
      "======================================================\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "WARNING: Set 'show_loss' to 'False' when not debugging. It will deteriorate the fitting performance.\n",
      "Alpha:[0.8399999 0.04      0.04      0.04      0.04     ]\n",
      "Training Loss: 0.0\n",
      "======================================================\n",
      "Accuracy: 0.9127977126517685\n",
      "======================================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train_t)):\n",
    "    x = np.asarray([X_train_t[i, :]])\n",
    "    y = np.asarray([y_train_t[i]])\n",
    "\n",
    "    arm, exp = gp.predict(x)\n",
    "\n",
    "    if arm == y[0]:  \n",
    "      gp.partial_fit(x, y, exp)\n",
    "\n",
    "    if i % 2000 == 1999:\n",
    "      pred = []\n",
    "      print(\"======================================================\")\n",
    "      for i in range(len(X_test_t)):  \n",
    "        pred.append(gp.predict(np.asarray([X_test_t[i, :]]))[0])\n",
    "      print(\"Accuracy: \" + str(balanced_accuracy_score(y_test_t, pred)))\n",
    "      print(\"======================================================\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3IBIV0WAqKI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ONN_Usage_Example.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
