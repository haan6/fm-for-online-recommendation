{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "@author: Yeji Han\n",
    "\n",
    "This script is used to preprocess the raw data file\n",
    "\"\"\"\n",
    "\n",
    "def load_criteo_category_index(file_path):\n",
    "    f = open(file_path, 'r')\n",
    "    cate_dict = []\n",
    "\n",
    "    for i in range(39):\n",
    "        cate_dict.append({})\n",
    "\n",
    "    for line in f:\n",
    "        data = line.strip().split(',')\n",
    "        cate_dict[int(data[0])][data[1]] = int(data[2])\n",
    "\n",
    "    return cate_dict\n",
    "\n",
    "def read_criteo_data(file_path, emb_file):\n",
    "    result = {'size': 0, 'label': [], 'index': [], 'value': [], 'feature_sizes':[]}\n",
    "    cate_dict = load_criteo_category_index(emb_file)\n",
    "\n",
    "    for item in cate_dict:\n",
    "        result['feature_sizes'].append(len(item))\n",
    "\n",
    "    f = open(file_path, 'r')\n",
    "    for line in f:\n",
    "        data = line.strip().split(',')\n",
    "        result['label'].append(int(data[0]))\n",
    "        indices = [int(item) for item in data[1:]]\n",
    "        values = [1 for i in range(39)]\n",
    "        result['index'].append(indices)\n",
    "        result['value'].append(values)\n",
    "\n",
    "    result['size'] += len(result['value'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "@author: Yeji Han\n",
    "\n",
    "A PyTorch implementation of Online FM\n",
    "\"\"\"\n",
    "\n",
    "from time import time\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch.backends.cudnn\n",
    "\n",
    "class FM(torch.nn.Module):\n",
    "    def __init__(self, field_size, feature_sizes, embedding_size=4, is_shallow_dropout=True,\n",
    "                 dropout_shallow=[0.5], n_epochs=64, batch_size=256, interaction_type=True,\n",
    "                 verbose=False, random_seed=990211, weight_decay=0.0, loss_type='logloss',\n",
    "                 b=0.99, n=0.01, eval_metric=roc_auc_score, use_cuda=True, greater_is_better=True):\n",
    "        super(FM, self).__init__()\n",
    "\n",
    "        # Check CUDA\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            print(\"Using CUDA\")\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "        self.field_size = field_size\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.is_shallow_dropout = is_shallow_dropout\n",
    "        self.dropout_shallow = dropout_shallow\n",
    "        self.batch_size = batch_size\n",
    "        self.interaction_type = interaction_type\n",
    "        self.n = n\n",
    "        self.verbose = verbose\n",
    "        self.weight_decay = weight_decay\n",
    "        self.random_seed = random_seed\n",
    "        self.loss_type = loss_type\n",
    "        self.eval_metric = eval_metric\n",
    "        self.use_cuda = use_cuda\n",
    "        self.greater_is_better = greater_is_better\n",
    "\n",
    "        self.b = Parameter(torch.tensor(b), requires_grad=False).to(self.device)\n",
    "\n",
    "        # FM\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, 1)\n",
    "                                                     for feature_size in self.feature_sizes]).to(self.device)\n",
    "        if self.dropout_shallow:\n",
    "            self.first_order_dropout = nn.Dropout(self.dropout_shallow[0]).to(self.device)\n",
    "\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size)\n",
    "                                                      for feature_size in self.feature_sizes]).to(self.device)\n",
    "\n",
    "    def forward(self, Xi, Xv):\n",
    "        first_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                               for i, emb in enumerate(self.first_order_embeddings)]\n",
    "        first_order = torch.cat(first_order_emb_arr, 1)\n",
    "\n",
    "        if self.dropout_shallow:\n",
    "            first_order = self.first_order_dropout(first_order)\n",
    "\n",
    "        if self.interaction_type:\n",
    "            # Use 2xixj = (xi+xj)^2 - xi^2 - yj^2 to reduce calculation\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            sum_second_order_emb = sum(second_order_emb_arr)\n",
    "            # (xi+xj)^2\n",
    "            sum_second_order_emb_square = sum_second_order_emb * sum_second_order_emb\n",
    "            # xi^2+xj^2\n",
    "            second_order_emb_square = [item * item for item in second_order_emb_arr]\n",
    "            second_order_emb_square_sum = sum(second_order_emb_square)\n",
    "            second_order = (sum_second_order_emb_square - second_order_emb_square_sum) * 0.5\n",
    "\n",
    "        else:\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            weights_fm = []\n",
    "            for i in range(self.field_size):\n",
    "                for j in range(i + 1, self.field_size):\n",
    "                    weights_fm.append(second_order_emb_arr[i] * second_order_emb_arr[j])\n",
    "\n",
    "        total_sum = self.b + torch.sum(first_order, 1) + torch.sum(second_order, 1)\n",
    "        return total_sum\n",
    "\n",
    "    def fit(self, Xi, Xv, Y):\n",
    "        Xi = Variable(torch.LongTensor(Xi).reshape(-1, self.field_size, 1)).to(self.device)\n",
    "        Xv = Variable(torch.FloatTensor(Xv).reshape(-1, self.field_size)).to(self.device)\n",
    "        Y = Variable(torch.FloatTensor(Y)).to(self.device)\n",
    "\n",
    "        model = self.train()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.n)\n",
    "        criterion = F.binary_cross_entropy_with_logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(Xi, Xv)\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    def predict(self, Xi_data, Xv_data):\n",
    "        Xi = Variable(torch.LongTensor(Xi_data).reshape(-1, self.field_size, 1)).to(self.device)\n",
    "        Xv = Variable(torch.FloatTensor(Xv_data).reshape(-1, self.field_size)).to(self.device)\n",
    "        model = self.eval()\n",
    "        output = model(Xi, Xv)\n",
    "        pred = torch.sigmoid(output).cpu()\n",
    "\n",
    "        return pred.data.numpy() > 0.5\n",
    "\n",
    "    def roc_score(self, pred, train_Y):\n",
    "        confusion_matrix = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "        for j in range(pred.shape[0]):\n",
    "            if pred[j] == train_Y[j]:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"tp\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"tn\"] += 1\n",
    "            else:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"fn\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"fp\"] += 1\n",
    "\n",
    "        if confusion_matrix['tp'] + confusion_matrix['fp'] != 0:\n",
    "            tpr = confusion_matrix['tp'] / (confusion_matrix['tp'] + confusion_matrix['fp'])\n",
    "        else:\n",
    "            tpr = 0\n",
    "\n",
    "        if confusion_matrix['fp'] + confusion_matrix['tn'] != 0:\n",
    "            fpr = confusion_matrix['fp'] / (confusion_matrix['fp'] + confusion_matrix['tn'])\n",
    "        else:\n",
    "            fpr = 0\n",
    "\n",
    "        return {\"tpr\": tpr, \"fpr\": fpr}\n",
    "\n",
    "    def evaluate(self, train_Xi, train_Xv, train_Y):\n",
    "        train_size = len(train_Y)\n",
    "        time_elapsed = 0\n",
    "        roc = []\n",
    "\n",
    "        start = time()\n",
    "        for i in range(train_size):\n",
    "            end = i + self.batch_size\n",
    "\n",
    "            if end < train_size:\n",
    "                self.fit(train_Xi[i:end], train_Xv[i:end], train_Y[i:end])\n",
    "            else:\n",
    "                self.fit(train_Xi[i:train_size], train_Xv[i:train_size], train_Y[i:train_size])\n",
    "\n",
    "            pred = self.predict(train_Xi, train_Xv)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                roc.append(self.roc_score(pred, train_Y))\n",
    "\n",
    "        time_elapsed = time() - start\n",
    "        return time_elapsed, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "@author: Yeji Han\n",
    "\n",
    "A PyTorch Implementation of Online NFM with Hedge Backpropagation\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch.backends.cudnn\n",
    "\n",
    "class ONN_NFM(torch.nn.Module):\n",
    "    def __init__(self, field_size, feature_sizes, max_num_hidden_layers, qtd_neuron_per_hidden_layer,\n",
    "                 dropout_shallow=[0.5], embedding_size=4, n_classes=2, batch_size=1,\n",
    "                 verbose=False, interaction_type=True, eval_metric=roc_auc_score,\n",
    "                 b=0.99, n=0.01, s=0.2, use_cuda=True, greater_is_better=True):\n",
    "        super(ONN_NFM, self).__init__()\n",
    "\n",
    "        # Check CUDA\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            print(\"Using CUDA\")\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "        self.field_size = field_size\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.max_num_hidden_layers = max_num_hidden_layers\n",
    "        self.qtd_neuron_per_hidden_layer = qtd_neuron_per_hidden_layer\n",
    "        self.dropout_shallow = dropout_shallow\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.interaction_type = interaction_type\n",
    "        self.eval_metric = eval_metric\n",
    "        self.use_cuda = use_cuda\n",
    "        self.greater_is_better = greater_is_better\n",
    "\n",
    "        self.b = Parameter(torch.tensor(b), requires_grad=False).to(self.device)\n",
    "        self.n = Parameter(torch.tensor(n), requires_grad=False).to(self.device)\n",
    "        self.s = Parameter(torch.tensor(s), requires_grad=False).to(self.device)\n",
    "\n",
    "        # FM Part\n",
    "        print(\"Initializing FM\")\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, 1)\n",
    "                                                     for feature_size in self.feature_sizes]).to(self.device)\n",
    "        if self.dropout_shallow:\n",
    "            self.first_order_dropout = nn.Dropout(self.dropout_shallow[0]).to(self.device)\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size)\n",
    "                                                      for feature_size in self.feature_sizes]).to(self.device)\n",
    "        self.bias = Parameter(torch.randn(1)).to(self.device)\n",
    "        print(\"Initializing FM Done\")\n",
    "\n",
    "        # Neural Networks Part\n",
    "        print(\"Initializing Neural Networks\")\n",
    "\n",
    "        self.hidden_layers = []\n",
    "        self.output_layers = []\n",
    "\n",
    "        if self.interaction_type:\n",
    "            self.hidden_layers.append(nn.Linear(embedding_size, qtd_neuron_per_hidden_layer))\n",
    "        else:\n",
    "            self.hidden_layers.append(\n",
    "                nn.Linear(self.field_size * (self.field_size - 1) / 2, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        for i in range(max_num_hidden_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(qtd_neuron_per_hidden_layer, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        for i in range(max_num_hidden_layers):\n",
    "            self.output_layers.append(nn.Linear(qtd_neuron_per_hidden_layer, n_classes))\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers).to(self.device)\n",
    "        self.output_layers = nn.ModuleList(self.output_layers).to(self.device)\n",
    "\n",
    "        self.alpha = Parameter(torch.Tensor(self.max_num_hidden_layers).fill_(1 / (self.max_num_hidden_layers + 1)),\n",
    "                               requires_grad=False).to(self.device)\n",
    "\n",
    "        self.loss_array = []\n",
    "\n",
    "        print(\"Initializing Neural Networks Done\")\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for i in range(self.max_num_hidden_layers):\n",
    "            self.output_layers[i].weight.grad.data.fill_(0)\n",
    "            self.output_layers[i].bias.grad.data.fill_(0)\n",
    "            self.hidden_layers[i].weight.grad.data.fill_(0)\n",
    "            self.hidden_layers[i].bias.grad.data.fill_(0)\n",
    "\n",
    "    def second_order(self, Xi, Xv):\n",
    "        # FM Part\n",
    "        Xi = torch.LongTensor(Xi).to(self.device).reshape(-1, self.field_size, 1)\n",
    "        Xv = torch.FloatTensor(Xv).to(self.device).reshape(-1, self.field_size)\n",
    "        second_order_emb_arr = [torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i].t()\n",
    "                                for i, emb in enumerate(self.second_order_embeddings)]\n",
    "        sum_second_order_emb = sum(second_order_emb_arr)\n",
    "        # (xi+xj)^2\n",
    "        sum_second_order_emb_square = sum_second_order_emb * sum_second_order_emb\n",
    "        # xi^2+xj^2\n",
    "        second_order_emb_square = [item * item for item in second_order_emb_arr]\n",
    "        second_order_emb_square_sum = sum(second_order_emb_square)\n",
    "        second_order = (sum_second_order_emb_square - second_order_emb_square_sum) * 0.5\n",
    "\n",
    "        return second_order.t()\n",
    "\n",
    "    def forward(self, Xi, Xv):\n",
    "        # Neural Networks Part\n",
    "        x = self.second_order(Xi, Xv)\n",
    "\n",
    "        hidden_connections = []\n",
    "        activation = F.relu\n",
    "\n",
    "        x = activation(self.hidden_layers[0](x))\n",
    "        hidden_connections.append(x)\n",
    "\n",
    "        for i in range(1, self.max_num_hidden_layers):\n",
    "            hidden_connections.append(\n",
    "                F.relu(self.hidden_layers[i](hidden_connections[i - 1])))\n",
    "\n",
    "        output_class = []\n",
    "        for i in range(self.max_num_hidden_layers):\n",
    "            output_class.append(self.output_layers[i](hidden_connections[i]))\n",
    "\n",
    "        pred_per_layer = torch.stack(output_class)\n",
    "        return pred_per_layer\n",
    "\n",
    "    def update_weights(self, Xi, Xv, Y, show_loss):\n",
    "        Y = torch.from_numpy(Y).to(self.device)\n",
    "        predictions_per_layer = self.forward(Xi, Xv)\n",
    "\n",
    "        losses_per_layer = []\n",
    "\n",
    "        for out in predictions_per_layer:\n",
    "            criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = criterion(out.view(self.batch_size, self.n_classes),\n",
    "                             Y.view(self.batch_size).long())\n",
    "            losses_per_layer.append(loss)\n",
    "\n",
    "        w = []\n",
    "        b = []\n",
    "\n",
    "        for i in range(len(losses_per_layer)):\n",
    "            losses_per_layer[i].backward(retain_graph=True)\n",
    "            self.output_layers[i].weight.data -= self.n * \\\n",
    "                                                 self.alpha[i] * self.output_layers[i].weight.grad.data\n",
    "            self.output_layers[i].bias.data -= self.n * \\\n",
    "                                               self.alpha[i] * self.output_layers[i].bias.grad.data\n",
    "            w.append(self.alpha[i] * self.hidden_layers[i].weight.grad.data)\n",
    "            b.append(self.alpha[i] * self.hidden_layers[i].bias.grad.data)\n",
    "            self.zero_grad()\n",
    "\n",
    "        for i in range(1, len(losses_per_layer)):\n",
    "            self.hidden_layers[i].weight.data -= self.n * torch.sum(torch.cat(w[i:]))\n",
    "            self.hidden_layers[i].bias.data -= self.n * torch.sum(torch.cat(b[i:]))\n",
    "\n",
    "        for i in range(len(losses_per_layer)):\n",
    "            self.alpha[i] *= torch.pow(self.b, losses_per_layer[i])\n",
    "            self.alpha[i] = torch.max(self.alpha[i], self.s / self.max_num_hidden_layers)\n",
    "\n",
    "        z_t = torch.sum(self.alpha)\n",
    "\n",
    "        self.alpha = Parameter(self.alpha / z_t, requires_grad=False).to(self.device)\n",
    "\n",
    "        if show_loss:\n",
    "            real_output = torch.sum(torch.mul(\n",
    "                self.alpha.view(self.max_num_hidden_layers, 1).repeat(1, self.batch_size).view(\n",
    "                    self.max_num_hidden_layers, self.batch_size, 1), predictions_per_layer), 0)\n",
    "            criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "            loss = criterion(real_output.view(self.batch_size, self.n_classes), Y.view(self.batch_size).long())\n",
    "            self.loss_array.append(loss)\n",
    "            if (len(self.loss_array) % 1000) == 0:\n",
    "                print(\"WARNING: Set 'show_loss' to 'False' when not debugging. \"\n",
    "                      \"It will deteriorate the fitting performance.\")\n",
    "                loss = torch.Tensor(self.loss_array).mean().cpu().numpy()\n",
    "                print(\"Alpha:\" + str(self.alpha.data.cpu().numpy()))\n",
    "                print(\"Training Loss: \" + str(loss))\n",
    "                self.loss_array.clear()\n",
    "\n",
    "    def partial_fit_(self, Xi_data, Xv_data, Y_data, show_loss=False):\n",
    "        self.update_weights(Xi_data, Xv_data, Y_data, show_loss)\n",
    "\n",
    "    def partial_fit(self, Xi_data, Xv_data, Y_data, show_loss=False):\n",
    "        self.partial_fit_(Xi_data, Xv_data, Y_data, show_loss)\n",
    "\n",
    "    def predict_(self, Xi_data, Xv_data):\n",
    "        return torch.argmax(torch.sum(torch.mul(\n",
    "            self.alpha.view(self.max_num_hidden_layers, 1).repeat(1, len(Xi_data)).view(\n",
    "                self.max_num_hidden_layers, len(Xi_data), 1), self.forward(Xi_data, Xv_data)), 0), dim=1).cpu().numpy()\n",
    "\n",
    "    def predict(self, Xi_data, Xv_data):\n",
    "        pred = self.predict_(Xi_data, Xv_data)\n",
    "        return pred\n",
    "\n",
    "    def roc_score(self, pred, train_Y):\n",
    "        confusion_matrix = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "\n",
    "        for j in range(pred.shape[0]):\n",
    "            if pred[j] == train_Y[j]:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"tp\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"tn\"] += 1\n",
    "            else:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"fn\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"fp\"] += 1\n",
    "\n",
    "        if confusion_matrix['tp'] + confusion_matrix['fp'] != 0:\n",
    "            tpr = confusion_matrix['tp'] / (confusion_matrix['tp'] + confusion_matrix['fp'])\n",
    "        else:\n",
    "            tpr= 0\n",
    "\n",
    "        if confusion_matrix['fp'] + confusion_matrix['tn'] != 0:\n",
    "            fpr = confusion_matrix['fp'] / (confusion_matrix['fp'] + confusion_matrix['tn'])\n",
    "        else:\n",
    "            fpr = 0\n",
    "\n",
    "        return {\"tpr\": tpr, \"fpr\": fpr}\n",
    "\n",
    "    def evaluate(self, train_Xi, train_Xv, train_Y):\n",
    "        roc = []\n",
    "        time_elapsed = 0\n",
    "\n",
    "        start = time()\n",
    "        for i in range(len(train_Y)):\n",
    "            self.partial_fit(np.array(train_Xi[i]), np.array(train_Xv[i]), np.array(train_Y[i]))\n",
    "            pred = self.predict(train_Xi, train_Xv)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                roc.append(self.roc_score(pred, train_Y))\n",
    "\n",
    "        time_elapsed = time() - start\n",
    "        return time_elapsed, roc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "@author: Yeji Han\n",
    "\n",
    "A PyTorch implementation of Online NFM with SGD\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.backends.cudnn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class SGD_NFM(torch.nn.Module):\n",
    "    def __init__(self, field_size, feature_sizes, max_num_hidden_layers, qtd_neuron_per_hidden_layer,\n",
    "                 dropout_shallow=[0.5], embedding_size=4, n_classes=2, n_epochs=64, batch_size=100,\n",
    "                 loss_type='logloss', verbose=False, interaction_type=True, eval_metric=accuracy_score,\n",
    "                 b=0.99, n=0.01, s=0.2, use_cuda=True, greater_is_better=True):\n",
    "\n",
    "        super(SGD_NFM, self).__init__()\n",
    "\n",
    "        # Check CUDA\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            print(\"Using CUDA\")\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "        self.field_size = field_size\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.max_num_hidden_layers = max_num_hidden_layers\n",
    "        self.qtd_neuron_per_hidden_layer = qtd_neuron_per_hidden_layer\n",
    "        self.dropout_shallow = dropout_shallow\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_type = loss_type\n",
    "        self.verbose = verbose\n",
    "        self.interaction_type = interaction_type\n",
    "        self.eval_metric = eval_metric\n",
    "        self.use_cuda = use_cuda\n",
    "        self.greater_is_better = greater_is_better\n",
    "        self.n = n\n",
    "\n",
    "        self.b = Parameter(torch.tensor(b), requires_grad=False).to(self.device)\n",
    "\n",
    "        # FM part\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, 1)\n",
    "                                                     for feature_size in self.feature_sizes]).to(self.device)\n",
    "        if self.dropout_shallow:\n",
    "            self.first_order_dropout = nn.Dropout(self.dropout_shallow[0]).to(self.device)\n",
    "\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size)\n",
    "                                                      for feature_size in self.feature_sizes]).to(self.device)\n",
    "\n",
    "        # Neural Networks\n",
    "        self.hidden_layers = []\n",
    "\n",
    "        if self.interaction_type:\n",
    "            self.hidden_layers.append(nn.Linear(embedding_size, qtd_neuron_per_hidden_layer))\n",
    "        else:\n",
    "            self.hidden_layers.append(\n",
    "                nn.Linear(self.field_size * (self.field_size - 1) / 2, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        for i in range(max_num_hidden_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(qtd_neuron_per_hidden_layer, qtd_neuron_per_hidden_layer))\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers).to(self.device)\n",
    "\n",
    "    def forward(self, Xi, Xv):\n",
    "        # FM\n",
    "        first_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                               for i, emb in enumerate(self.first_order_embeddings)]\n",
    "        first_order = torch.cat(first_order_emb_arr, 1)\n",
    "\n",
    "        if self.dropout_shallow:\n",
    "            first_order = self.first_order_dropout(first_order)\n",
    "\n",
    "        if self.interaction_type:\n",
    "            # Use 2xixj = (xi+xj)^2 - xi^2 - yj^2 to reduce calculation\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            sum_second_order_emb = sum(second_order_emb_arr)\n",
    "            # (xi+xj)^2\n",
    "            sum_second_order_emb_square = sum_second_order_emb * sum_second_order_emb\n",
    "            # xi^2+xj^2\n",
    "            second_order_emb_square = [item * item for item in second_order_emb_arr]\n",
    "            second_order_emb_square_sum = sum(second_order_emb_square)\n",
    "            second_order = (sum_second_order_emb_square - second_order_emb_square_sum) * 0.5\n",
    "\n",
    "        else:\n",
    "            second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t()\n",
    "                                    for i, emb in enumerate(self.second_order_embeddings)]\n",
    "            weights_fm = []\n",
    "            for i in range(self.field_size):\n",
    "                for j in range(i + 1, self.field_size):\n",
    "                    weights_fm.append(second_order_emb_arr[i] * second_order_emb_arr[j])\n",
    "\n",
    "        # Neural Networks\n",
    "        if self.interaction_type:\n",
    "            x = second_order\n",
    "        else:\n",
    "            x = torch.cat([torch.sum(weight_fm, 1).view([-1, 1])\n",
    "                           for weight_fm in weights_fm], 1)\n",
    "\n",
    "        activation = F.relu\n",
    "        for i in range(self.max_num_hidden_layers):\n",
    "            x = activation(self.hidden_layers[i](x))\n",
    "\n",
    "        # Sum\n",
    "        total_sum = self.b + torch.sum(first_order, 1) + torch.sum(x, 1)\n",
    "        return total_sum\n",
    "\n",
    "    def fit(self, Xi, Xv, Y):\n",
    "        Xi = Variable(torch.LongTensor(Xi).reshape(-1, self.field_size, 1)).to(self.device)\n",
    "        Xv = Variable(torch.FloatTensor(Xv).reshape(-1, self.field_size)).to(self.device)\n",
    "        Y = Variable(torch.FloatTensor(Y)).to(self.device)\n",
    "\n",
    "        model = self.train()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.n)\n",
    "        criterion = F.binary_cross_entropy_with_logits\n",
    "\n",
    "        epoch_begin_time = time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(Xi, Xv)\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    def predict(self, Xi_data, Xv_data):\n",
    "        Xi = Variable(torch.LongTensor(Xi_data).reshape(-1, self.field_size, 1)).to(self.device)\n",
    "        Xv = Variable(torch.FloatTensor(Xv_data).reshape(-1, self.field_size)).to(self.device)\n",
    "\n",
    "        model = self.eval()\n",
    "        output = model(Xi, Xv)\n",
    "        pred = torch.sigmoid(output).cpu()\n",
    "        return pred.data.numpy() > 0.5\n",
    "\n",
    "    def roc_score(pred, train_Y):\n",
    "        confusion_matrix = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "\n",
    "        for j in range(pred):\n",
    "            if pred[j] == train_Y[j]:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"tp\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"tn\"] += 1\n",
    "            else:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"fn\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"fp\"] += 1\n",
    "\n",
    "        tpr = confusion_matrix['tp'] / (confusion_matrix['tp'] + confusion_matrix['fp'])\n",
    "        fpr = confusion_matrix['fp'] / (confusion_matrix['fp'] + confusion_matrix['tn'])\n",
    "\n",
    "        return {\"tpr\": tpr, \"fpr\": fpr}\n",
    "\n",
    "    def roc_score(self, pred, train_Y):\n",
    "        confusion_matrix = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "\n",
    "        for j in range(pred.shape[0]):\n",
    "            if pred[j] == train_Y[j]:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"tp\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"tn\"] += 1\n",
    "            else:\n",
    "                if train_Y[j] == 1:\n",
    "                    confusion_matrix[\"fn\"] += 1\n",
    "                else:\n",
    "                    confusion_matrix[\"fp\"] += 1\n",
    "\n",
    "        if confusion_matrix['tp'] + confusion_matrix['fp'] != 0:\n",
    "            tpr = confusion_matrix['tp'] / (confusion_matrix['tp'] + confusion_matrix['fp'])\n",
    "        else:\n",
    "            tpr = 0\n",
    "\n",
    "        if confusion_matrix['fp'] + confusion_matrix['tn'] != 0:\n",
    "            fpr = confusion_matrix['fp'] / (confusion_matrix['fp'] + confusion_matrix['tn'])\n",
    "        else:\n",
    "            fpr = 0\n",
    "\n",
    "        return {\"tpr\": tpr, \"fpr\": fpr}\n",
    "\n",
    "    def evaluate(self, train_Xi, train_Xv, train_Y):\n",
    "        train_size = len(train_Y)\n",
    "        time_elapsed = 0\n",
    "        confusion_matrix = {\n",
    "            \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0\n",
    "        }\n",
    "        roc = []\n",
    "\n",
    "        start = time()\n",
    "        for i in range(train_size):\n",
    "            end = i + self.batch_size\n",
    "            if end < train_size:\n",
    "                self.fit(train_Xi[i:end], train_Xv[i:end], train_Y[i:end])\n",
    "            else:\n",
    "                self.fit(train_Xi[i:train_size], train_Xv[i:train_size], train_Y[i:train_size])\n",
    "\n",
    "            pred = self.predict(train_Xi, train_Xv)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                roc.append(self.roc_score(pred, train_Y))\n",
    "\n",
    "\n",
    "        time_elapsed = time() - start\n",
    "        return time_elapsed, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Importing Dataset =====\n",
      "===== Dataset is Ready =====\n",
      "===== Instantiating Models =====\n",
      "Using CUDA\n",
      "Using CUDA\n",
      "Using CUDA\n",
      "Initializing FM\n",
      "Initializing FM Done\n",
      "Initializing Neural Networks\n",
      "Initializing Neural Networks Done\n",
      "===== Models are Ready =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Importing Dataset =====\")\n",
    "\n",
    "train_dict = read_criteo_data('tiny_train_input.csv', 'category_emb.csv')\n",
    "train_dict_size = train_dict['size']\n",
    "\n",
    "train_Xi, train_Xv, train_Y \\\n",
    "    = train_dict['index'][:int(train_dict_size * 0.05)], \\\n",
    "      train_dict['value'][:int(train_dict_size * 0.05)], \\\n",
    "      train_dict['label'][:int(train_dict_size * 0.05)]\n",
    "\n",
    "print(\"===== Dataset is Ready =====\")\n",
    "\n",
    "# with torch.cuda.device(0):\n",
    "time_elapsed = {\"FM\": 0, \"SGD_NFM\": 0, \"ONN_NFM\": 0}\n",
    "roc_scores = {\"FM\": [], \"SGD_NFM\": [], \"ONN_NFM\": []}\n",
    "\n",
    "print(\"===== Instantiating Models =====\")\n",
    "\n",
    "fm = FM(39, train_dict['feature_sizes'], batch_size=20)\n",
    "sgd_nfm = SGD_NFM(39, train_dict['feature_sizes'], 5, 10, batch_size=20)\n",
    "onn_nfm = ONN_NFM(39, train_dict['feature_sizes'], max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=10,\n",
    "                  verbose=True, use_cuda=True, interaction_type=True)\n",
    "\n",
    "models = [(fm, \"FM\"), (sgd_nfm, \"SGD_NFM\"), (onn_nfm, \"ONN_NFM\")]\n",
    "\n",
    "print(\"===== Models are Ready =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training FM =====\n",
      "===== Evaluating FM is Finished. Time: 891.9832229614258 =====\n"
     ]
    }
   ],
   "source": [
    "print(f\"===== Training FM =====\")\n",
    "time_elapsed[models[0][1]], roc_scores[models[0][1]] = models[0][0].evaluate(train_Xi, train_Xv, train_Y)\n",
    "print(f\"===== Evaluating FM is Finished. Time: {time_elapsed[models[0][1]]} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training SGD_NFM =====\n",
      "===== Evaluating SGD_NFM is Finished. Time: 891.5925273895264 =====\n"
     ]
    }
   ],
   "source": [
    "print(f\"===== Training SGD_NFM =====\")\n",
    "time_elapsed[models[1][1]], roc_scores[models[1][1]] = models[1][0].evaluate(train_Xi, train_Xv, train_Y)\n",
    "print(f\"===== Evaluating SGD_NFM is Finished. Time: {time_elapsed[models[1][1]]} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training ONN_NFM =====\n",
      "===== Evaluating ONN_NFM is Finished. Time: 1043.663141489029 =====\n"
     ]
    }
   ],
   "source": [
    "print(f\"===== Training ONN_NFM =====\")\n",
    "time_elapsed[models[2][1]], roc_scores[models[2][1]] = models[2][0].evaluate(train_Xi, train_Xv, train_Y)\n",
    "print(f\"===== Evaluating ONN_NFM is Finished. Time: {time_elapsed[models[2][1]]} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Drawing a plot =====\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"===== Drawing a plot =====\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime('%Y-%m-%d')\n",
    "\n",
    "plt.ylim(-0.04, 1.04)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.grid()\n",
    "\n",
    "for i, (mark, color) in enumerate(zip(\n",
    "        ['s', 'o', 'v'], ['r', 'g', 'b'])):\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "\n",
    "    for j in range(len(roc_scores[models[i][1]])):\n",
    "        tpr.append([roc_scores[models[i][1]][j][\"tpr\"]])\n",
    "        fpr.append([roc_scores[models[i][1]][j][\"fpr\"]])\n",
    "        plt.plot(fpr, tpr, color=color,\n",
    "                marker=mark,\n",
    "                markerfacecolor='None',\n",
    "                markeredgecolor=color,\n",
    "                linestyle='None',\n",
    "                label=models[i][0])\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], color='black', linewidth=2)\n",
    "plt.title('ROC Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'{date}_roc_score.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
