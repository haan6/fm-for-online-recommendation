{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.FM import *\n",
    "from model.SGD_NFM import *\n",
    "from model.ONN_NFM import *\n",
    "from data import data_preprocess\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Importing Dataset =====\n",
      "===== Dataset Ready -- # of Data: 23517 -- =====\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Importing Dataset =====\")\n",
    "\n",
    "train_dict = data_preprocess.balance_criteo_data('data/tiny_train_input.csv', 'data/category_emb.csv')\n",
    "train_dict_size = train_dict['size'] * 0.1\n",
    "\n",
    "train_Xi, train_Xv, train_Y \\\n",
    "    = train_dict['index'][:int(train_dict_size)], \\\n",
    "      train_dict['value'][:int(train_dict_size)], \\\n",
    "      train_dict['label'][:int(train_dict_size)]\n",
    "\n",
    "print(f\"===== Dataset Ready -- # of Data: {int(train_dict_size)} -- =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Instantiating Models =====\n",
      "FM: Using CUDA\n",
      "SGD NFM:  CUDA\n",
      "ONN NFM: Using CUDA\n",
      "===== Models Ready =====\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    time_elapsed = {\"FM\": 0, \"SGD_NFM\": 0, \"ONN_NFM\": 0}\n",
    "    accuracy_scores = {\"FM\": [], \"SGD_NFM\": [], \"ONN_NFM\": []}\n",
    "    roc_scores = {\"FM\": [], \"SGD_NFM\": [], \"ONN_NFM\": []}\n",
    "\n",
    "    print(\"===== Instantiating Models =====\")\n",
    "\n",
    "    fm = FM(39, train_dict['feature_sizes'], batch_size=20)\n",
    "    sgd_nfm = SGD_NFM(39, train_dict['feature_sizes'], 5, 10, batch_size=20)\n",
    "    onn_nfm = ONN_NFM(39, train_dict['feature_sizes'], max_num_hidden_layers=5, qtd_neuron_per_hidden_layer=10,\n",
    "                      verbose=True, use_cuda=True, interaction_type=True)\n",
    "\n",
    "    models = [(fm, \"FM\"), (sgd_nfm, \"SGD_NFM\"), (onn_nfm, \"ONN_NFM\")]\n",
    "\n",
    "    print(\"===== Models Ready =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    time_elapsed['FM'], accuracy_scores['FM'], roc_scores['FM'] = fm.evaluate(train_Xi, train_Xv, train_Y)\n",
    "    print(f\"Evaluating FM Done. Time Elapsed: {time_elapsed['FM'] // 60}m {time_elapsed['FM'] % 60}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    time_elapsed['SGD_NFM'], accuracy_scores['SGD_NFM'], roc_scores['SGD_NFM'] = sgd_nfm.evaluate(train_Xi, train_Xv, train_Y)\n",
    "    print(f\"Evaluating SGD_NFM Done. Time Elapsed: {time_elapsed['SGD_NFM'] // 60}m {time_elapsed['SGD_NFM'] % 60}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    time_elapsed['ONN_NFM'], accuracy_scores['ONN_NFM'], roc_scores['ONN_NFM'] = sgd_nfm.evaluate(train_Xi, train_Xv, train_Y)\n",
    "    print(f\"Evaluating ONN_NFM Done. Time Elapsed: {time_elapsed['ONN_NFM'] // 60}m {time_elapsed['ONN_NFM'] % 60}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for i, model in enumerate(models):\n",
    "#         print(f\"===== Training {models[i][1]} =====\")\n",
    "#         time_elapsed[models[i][1]], accuracy_scores[models[i][1]], roc_scores[models[i][1]] = models[i][0].evaluate(train_Xi, train_Xv, train_Y)\n",
    "#         print(f\"Evaluating {models[i][1]} Done. Time Elapsed: {int(time_elapsed[models[i][1]] / 60)}m {time_elapsed[models[i][1]] - 60 * int(time_elapsed[models[i][1]] / 60)}s\")\n",
    "\n",
    "#     print(\"===== Training Models Done =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"===== Drawing Accuracy Plot =====\")\n",
    "    acc_fig = plt.figure() \n",
    "    roc_fig.ylim(-4, 104)\n",
    "    colors = ['r', 'g', 'b']\n",
    "    \n",
    "    for i, color in enumerate(colors):\n",
    "        acc_fig.plot([j for j in range(len(accracy_scores[models[i][1]]))], auccracy_scores[models[i][1]],\n",
    "                     color=color, label=models[i][0]):\n",
    "            \n",
    "    acc_fig.title('Accuracy Score')\n",
    "    acc_fig.legend(loc='lower right')\n",
    "    acc_fig.savefig(f'{date}_accuracy_score.png')\n",
    "    \n",
    "    acc_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"===== Drawing ROC Plot =====\")\n",
    "    roc_fig = plt.figure()\n",
    "\n",
    "    roc_fig.set_aspect('equal')\n",
    "    x = np.linspace(*ax.get_xlim())\n",
    "    roc_fig.plot(x, x, color='black')\n",
    "\n",
    "    roc_fig.ylim(-0.04, 1.04)\n",
    "    roc_fig.xlabel('FPR')\n",
    "    roc_fig.ylabel('TPR')\n",
    "\n",
    "    for i, (mark, color) in enumerate(zip(\n",
    "            ['s', 'o', 'v'], ['r', 'g', 'b'])):\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "\n",
    "        for j in range(len(roc_scores[models[i][1]])):\n",
    "            tpr.append([roc_scores[models[i][1]][j][\"tpr\"]])\n",
    "            fpr.append([roc_scores[models[i][1]][j][\"fpr\"]])\n",
    "\n",
    "        roc_fig.plot(fpr, tpr, color=color,\n",
    "                marker=mark,\n",
    "                markerfacecolor='None',\n",
    "                markeredgecolor=color,\n",
    "                linestyle='None',\n",
    "                label=models[i][0])\n",
    "\n",
    "    roc_fig.title('ROC Score')\n",
    "    roc_fig.legend(loc='lower right')\n",
    "    roc_fig.savefig(f'{date}_roc_score.png')\n",
    "    \n",
    "    roc_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
